"""
Quick Demo: XAI Attribution Methods for Cat/Dog Classification

This script demonstrates how to use XAI methods to explain model predictions.
Run this to see attribution maps in action!
"""

import torch
from pathlib import Path
import sysq
import matplotlib.pyplot as plt

# Add project root to path
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.append(str(PROJECT_ROOT))

from src.models import build_model
from src.datasets import get_classification_transforms
from src.xai import AttributionEngine, visualize_multiple_attributions


def demo_xai():
    """Demo XAI attribution methods"""
    
    print("=" * 70)
    print("üî¨ XAI Attribution Demo for Cat/Dog Classification")
    print("=" * 70)
    
    # 1. Load model
    print("\n1Ô∏è‚É£ Loading model...")
    model_path = PROJECT_ROOT / "models/classification/best_model.pth"
    
    if not model_path.exists():
        print(f"‚ùå Model not found at: {model_path}")
        print("\nPlease download or train a model first:")
        print("  python scripts/train_classification.py")
        return
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"   Using device: {device}")
    
    model = build_model(
        task="classification",
        model_name="resnet18",
        num_classes=2
    )
    
    checkpoint = torch.load(model_path, map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.to(device)
    model.eval()
    print("   ‚úÖ Model loaded")
    
    # 2. Initialize XAI engine
    print("\n2Ô∏è‚É£ Initializing XAI Attribution Engine...")
    
    xai_engine = AttributionEngine(
        model=model,
        device=device,
        task="classification"
    )
    print("   ‚úÖ XAI engine ready")
    print(f"   Available methods: {list(xai_engine.methods.keys())}")
    
    # 3. Find a test image
    print("\n3Ô∏è‚É£ Finding test image...")
    test_dir = PROJECT_ROOT / "data/classification/test"
    
    test_image = None
    if test_dir.exists():
        # Try to find a cat image
        for subdir in test_dir.iterdir():
            if subdir.is_dir():
                images = list(subdir.glob("*.jpg"))
                if images:
                    test_image = images[0]
                    break
    
    if test_image is None:
        print("   ‚ùå No test images found")
        print(f"   Expected location: {test_dir}")
        print("\n   Please add some test images or specify a custom path:")
        print("   python scripts/predict_image.py YOUR_IMAGE.jpg --xai")
        return
    
    print(f"   üì∏ Using: {test_image.name}")
    
    # 4. Load and preprocess image
    print("\n4Ô∏è‚É£ Loading and preprocessing image...")
    from PIL import Image
    
    img = Image.open(test_image).convert('RGB')
    transform = get_classification_transforms('val', 224)
    img_tensor = transform(img).to(device)
    print("   ‚úÖ Image preprocessed")
    
    # 5. Make prediction
    print("\n5Ô∏è‚É£ Making prediction...")
    with torch.no_grad():
        output = model(img_tensor.unsqueeze(0))
        probs = torch.nn.functional.softmax(output, dim=1)
        pred_class = torch.argmax(probs, dim=1).item()
        confidence = probs[0][pred_class].item() * 100
    
    class_names = ['cat', 'dog']
    class_emojis = ['üê±', 'üê∂']
    
    print(f"   Prediction: {class_emojis[pred_class]} {class_names[pred_class].upper()}")
    print(f"   Confidence: {confidence:.2f}%")
    print(f"   Probabilities:")
    print(f"     üê± Cat: {probs[0][0].item() * 100:.2f}%")
    print(f"     üê∂ Dog: {probs[0][1].item() * 100:.2f}%")
    
    # 6. Compute attribution maps
    print("\n6Ô∏è‚É£ Computing XAI attribution maps...")
    print("   This may take a few moments...")
    
    methods = ['integrated_gradients', 'gradient_shap', 'saliency']
    attributions = {}
    
    for method in methods:
        print(f"   üîÑ Computing {method}...")
        try:
            attr = xai_engine.get_attribution(
                img_tensor,
                method=method,
                target=pred_class
            )
            attributions[method] = attr
            print(f"   ‚úÖ {method} complete")
        except Exception as e:
            print(f"   ‚ùå Failed: {e}")
    
    if not attributions:
        print("\n‚ùå No attributions were computed successfully")
        return
    
    # 7. Visualize results
    print("\n7Ô∏è‚É£ Generating visualization...")
    output_path = PROJECT_ROOT / "results/xai_demo.png"
    output_path.parent.mkdir(exist_ok=True)
    
    visualize_multiple_attributions(
        img_tensor,
        attributions,
        save_path=str(output_path)
    )
    
    print(f"   ‚úÖ Saved visualization to: {output_path}")
    
    # 8. Summary
    print("\n" + "=" * 70)
    print("üéâ XAI Demo Complete!")
    print("=" * 70)
    print("\nüìä What we did:")
    print("  1. Loaded a trained Cat/Dog classifier")
    print("  2. Made a prediction on a test image")
    print("  3. Generated attribution maps using multiple XAI methods")
    print("  4. Visualized which image regions influenced the prediction")
    
    print("\nüî¨ Understanding the Results:")
    print("  ‚Ä¢ Red/Hot regions = High importance (influenced prediction)")
    print("  ‚Ä¢ Blue/Cold regions = Low importance (little influence)")
    print("  ‚Ä¢ Different methods may highlight different features")
    
    print("\nüí° Next Steps:")
    print("  ‚Ä¢ Try on your own images:")
    print("    python scripts/predict_image.py YOUR_IMAGE.jpg --xai")
    print("\n  ‚Ä¢ Analyze misclassifications:")
    print("    python scripts/predict_image.py wrong_prediction.jpg --xai")
    print("\n  ‚Ä¢ Batch process test set:")
    print("    python scripts/run_xai.py task=classification")
    
    print("\nüìñ Learn more: See QUICKSTART_XAI.md for detailed guide")
    print("=" * 70)


if __name__ == "__main__":
    try:
        demo_xai()
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è Demo interrupted by user")
    except Exception as e:
        print(f"\n\n‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
        print("\nüí° Tip: Make sure you have:")
        print("  1. A trained model in models/classification/best_model.pth")
        print("  2. Test images in data/classification/test/")
        print("  3. Required packages: pip install -r requirements.txt")
